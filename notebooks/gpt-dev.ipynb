{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following along https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing but with JAX/Flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python@3.12/3.12.7_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1089k  100 1089k    0     0  2185k      0 --:--:-- --:--:-- --:--:-- 2187k\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!curl https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -o data/tinyshakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n",
      "Vocabulary size: 65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "with open('data/tinyshakespeare') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print('Corpus size: ' + str(len(text)))\n",
    "print(text[:1000])\n",
    "\n",
    "vocab = list(set(text))\n",
    "vocab_size = len(vocab)\n",
    "print('Vocabulary size: ' + str(len(vocab)))\n",
    "print(''.join(sorted(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "itos = {i:s for i,s in enumerate(vocab)}\n",
    "stoi = {s:i for i,s in enumerate(vocab)}\n",
    "\n",
    "encode = lambda x: [stoi[s] for s in x]\n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "\n",
    "print(decode(encode('hello world')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "(1115394,)\n",
      "[48 34 40 59 24 18 23 34 24 34 32 55 26  7  1 25 55 44 50 40 55 18 56 55\n",
      " 18 49 40 50  5 55 55  9 18 42 26  0 18 44 57 40 24 12 55 40 13 18 12 55\n",
      " 42 40 18  4 55 18 59 49 55 42  2 54  1  1 60 11 11  7  1 37 49 55 42  2\n",
      " 13 18 59 49 55 42  2 54  1  1 48 34 40 59 24 18 23 34 24 34 32 55 26  7\n",
      "  1 30 50 57]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "data = jnp.array(encode(text), dtype=jnp.int32)\n",
    "print(data.dtype)\n",
    "print(data.shape)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[: int(.9 * len(data))]\n",
    "val_data = data[int(.9 * len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Array([[18,  4, 42, 26, 24, 11, 55,  1],\n",
      "       [27, 14, 36,  7,  1, 36, 13, 18],\n",
      "       [34,  4, 54,  1, 25, 57, 24, 18],\n",
      "       [18, 59, 57,  5, 12, 18, 11, 55]], dtype=int32), Array([[ 4, 42, 26, 24, 11, 55,  1, 50],\n",
      "       [14, 36,  7,  1, 36, 13, 18, 11],\n",
      "       [ 4, 54,  1, 25, 57, 24, 18, 12],\n",
      "       [59, 57,  5, 12, 18, 11, 55, 26]], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "dynamic_slice_vmap = jax.vmap(jax.lax.dynamic_slice, in_axes=(None, 0, None))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_batch(data, key):\n",
    "    ix = jax.random.randint(key, shape=(batch_size, 1), minval=0, maxval=len(data) - block_size)\n",
    "    x = dynamic_slice_vmap(data, ix, (block_size,))\n",
    "    y = dynamic_slice_vmap(data, ix + 1, (block_size,))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "key = jax.random.key(1337)\n",
    "print(get_batch(train_data, key))\n",
    "xb, yb = get_batch(train_data, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx\n",
    "import optax\n",
    "\n",
    "class BigramLanguageModel(nnx.Module):\n",
    "    rngs: nnx.Rngs\n",
    "\n",
    "    def __init__(self, vocab_size, n_embed, rngs: nnx.Rngs):\n",
    "        self.rngs = rngs\n",
    "        # TODO: Something is off since certain values of n_embed is causing loss to be NaN.\n",
    "        self.token_embedding_table = nnx.Embed(num_embeddings=vocab_size, features=n_embed, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        logits = self.token_embedding_table(x)\n",
    "        return logits\n",
    "    \n",
    "    def generate(self, x, length): # x has the shape (batch_size, block_size)\n",
    "        for i in range(length):\n",
    "            logits = self(x)\n",
    "            next_token = jax.random.categorical(self.rngs.next(), logits[:, -1])\n",
    "            x = jnp.concatenate([x, next_token[:, None]], axis=1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "key = jax.random.key(1337)\n",
    "rngs = nnx.Rngs(key)\n",
    "model = BigramLanguageModel(vocab_size, 32, rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4952408\n",
      "0.47264346\n",
      "[[ 4 42 26 24 11 55  1 50]\n",
      " [14 36  7  1 36 13 18 11]\n",
      " [ 4 54  1 25 57 24 18 12]\n",
      " [59 57  5 12 18 11 55 26]]\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "def loss(model, x, targets):\n",
    "        logits = model(x)\n",
    "        print(jnp.min(logits))\n",
    "        print(jnp.max(logits))\n",
    "        print(targets)\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(logits, targets).mean()\n",
    "\n",
    "print(loss(model, xb, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x14f7215a0>, in_tracers=(Traced<ShapedArray(float32[4,8,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,8,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x14f85ea20; to 'JaxprTracer' at 0x14f85e940>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[4,8,32] b:f32[4,8,32] c:f32[]. let\n",
      "    d:f32[4,8,32] = mul a b\n",
      "    e:f32[] = reduce_sum[axes=(0, 1, 2)] d\n",
      "    f:f32[] = div e c\n",
      "  in (f,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False, False), 'name': '_reduce_min', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fc84be90a40>, name_stack=NameStack(stack=(Transform(name='jvp'),))), ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x14f7216c0>, in_tracers=(Traced<ShapedArray(float32[4,8,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,8,32]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x14f85fba0; to 'JaxprTracer' at 0x14f85fac0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[4,8,32] b:f32[4,8,32] c:f32[]. let\n",
      "    d:f32[4,8,32] = mul a b\n",
      "    e:f32[] = reduce_sum[axes=(0, 1, 2)] d\n",
      "    f:f32[] = div e c\n",
      "  in (f,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False, False), 'name': '_reduce_max', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7fc7e5a1d6c0>, name_stack=NameStack(stack=(Transform(name='jvp'),))), ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Traced<ShapedArray(int32[4,8])>with<DynamicJaxprTrace(level=1/0)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:00<46:40,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4962408\n",
      "0.47164348\n",
      "[[52 50 59 24 13 18 11 55]\n",
      " [42 26  9 18  9 55 42 24]\n",
      " [34 26 62 18 12 55 40 18]\n",
      " [18 38 40 50 24 12 55 40]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1092/10000 [00:01<00:11, 767.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2612628\n",
      "0.854791\n",
      "[[26 18 50 57 24 47  1 28]\n",
      " [34  4 55 13  1 60 26  9]\n",
      " [57 40 55 47 18  4  0 18]\n",
      " [42 11 11 18 24 12 55  4]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2113/10000 [00:03<00:09, 864.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9625386\n",
      "1.2824993\n",
      "[[26 18 42 40  4 59 54  1]\n",
      " [42 38 11 55 18  5 50 57]\n",
      " [ 9 13 18 24 12 50 57 62]\n",
      " [40 55 18  0 50 57 40 18]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 3146/10000 [00:04<00:09, 755.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.641821\n",
      "1.4377373\n",
      "[[15 60 61 18 43 36 64 51]\n",
      " [40 42  4 55 18 24 50 18]\n",
      " [18 23 11 42 57  9 34 50]\n",
      " [ 1 39 12 42 24 18 59 12]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 4130/10000 [00:05<00:07, 774.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.2882185\n",
      "1.4454585\n",
      "[[42  9 55 18 44 42 34 40]\n",
      " [57 18  4  0 18 12 55 11]\n",
      " [55  0 18  3 42 40  1 39]\n",
      " [18  5 50  4 55 18 42 62]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5108/10000 [00:07<00:06, 779.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.9214413\n",
      "1.877178\n",
      "[[51 17 18 64 14 51 61 30]\n",
      " [40  2  8  1  1 27 14 51]\n",
      " [12 55 26 13 18 50 57 40]\n",
      " [50  4 18  0 50 57 18 12]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 6149/10000 [00:08<00:05, 765.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.5589967\n",
      "2.0489893\n",
      "[[ 9 18 42 38 57 59 55 18]\n",
      " [55 13  1 64 42 40 49 18]\n",
      " [11  9 18 34 26  5 40 55]\n",
      " [18 38 55 18  9 34 59 12]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7081/10000 [00:09<00:05, 547.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.2123175\n",
      "1.4436244\n",
      "[[50 57 47 18  4 42  0 18]\n",
      " [ 0  1 59 56 55 55 24 18]\n",
      " [18 55 26 59 57 55 18 12]\n",
      " [42 26  9 18 12 34 59 18]]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7894/10000 [00:11<00:03, 693.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[356], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m key, subkey \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[1;32m     11\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_batch(train_data, subkey)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss(model, xb, yb))\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/flax/nnx/nnx/graph.py:1043\u001b[0m, in \u001b[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_context_manager_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1042\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/flax/nnx/nnx/transforms/transforms.py:355\u001b[0m, in \u001b[0;36mjit.<locals>.jit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;129m@graph\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    354\u001b[0m   ctx \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mcurrent_update_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 355\u001b[0m   (args, kwargs), input_graph_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_graph_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m   graphdef, state \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39msplit(input_graph_nodes)\n\u001b[1;32m    359\u001b[0m   out, output_state, output_graphdef \u001b[38;5;241m=\u001b[39m jitted_fn(\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    361\u001b[0m     _nnx_jit_static\u001b[38;5;241m=\u001b[39mJitStaticInputs(graphdef, _constrain_state, fun),\n\u001b[1;32m    362\u001b[0m     _nnx_jit_state\u001b[38;5;241m=\u001b[39mstate,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    364\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/flax/nnx/nnx/graph.py:1626\u001b[0m, in \u001b[0;36mextract_graph_nodes\u001b[0;34m(pytree)\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GraphNodeIndex(index)\n\u001b[1;32m   1624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m-> 1626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_maybe_extract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpytree\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mtuple\u001b[39m(nodes)\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/jax/_src/tree_util.py:343\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    341\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    342\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_leaves\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/jax/_src/tree_util.py:343\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    341\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    342\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/flax/nnx/nnx/graph.py:1620\u001b[0m, in \u001b[0;36mextract_graph_nodes.<locals>._maybe_extract\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_graph_node(x):\n\u001b[1;32m   1619\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m-> 1620\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(nodes)\n\u001b[1;32m   1621\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1622\u001b[0m     index \u001b[38;5;241m=\u001b[39m nodes[x]\n",
      "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/flax/nnx/nnx/graph.py:112\u001b[0m, in \u001b[0;36mRefMap.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _HashById(key) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: A, value: B):\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping[_HashById(key)] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__delitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: A):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = nnx.Optimizer(model, optax.adam(1e-3))\n",
    "batch_size = 32\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, xb, yb):\n",
    "    grads = (nnx.grad(loss))(model, xb, yb)\n",
    "    optimizer.update(grads)\n",
    "\n",
    "for i in tqdm.trange(10000):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    xb, yb = get_batch(train_data, subkey)\n",
    "    train_step(model, optimizer, xb, yb)\n",
    "    if i % 1000 == 0:\n",
    "        print(loss(model, xb, yb))\n",
    "print(loss(model, xb, yb))\n",
    "\n",
    "val_xb, val_yb = get_batch(val_data, key)\n",
    "print(loss(model, val_xb, val_yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "IWhym m,\n",
      "\n",
      "CL:\n",
      "Bl my m:\n",
      "'tll m! th yEYy, ty ck CLE:\n",
      "\n",
      "Cm thl ck:\n",
      "\n",
      "CKI hth dm,\n",
      "DKILY!\n",
      "\n",
      "Wh, th\n",
      "I cQYhy,\n"
     ]
    }
   ],
   "source": [
    "print([decode(row.tolist()) for row in model.generate(jnp.zeros((1, 1), dtype=jnp.int32), 100)][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
